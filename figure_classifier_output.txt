{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=550x442 at 0x15312AEF2ED0>, 'label': 0, 'pixel_values': tensor([[[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],
         [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],
         [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],
         ...,
         [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],
         [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],
         [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489]],

        [[2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],
         [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],
         [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],
         ...,
         [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],
         [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286],
         [2.4286, 2.4286, 2.4286,  ..., 2.4286, 2.4286, 2.4286]],

        [[2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],
         [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],
         [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],
         ...,
         [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],
         [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400],
         [2.6400, 2.6400, 2.6400,  ..., 2.6400, 2.6400, 2.6400]]])}
Printing the shape of the tensor
pixel_values torch.Size([4, 3, 224, 224])
******************************************************************************************************************************************************
Printing the shape of the tensor
labels torch.Size([4])
******************************************************************************************************************************************************
{'eval_loss': 0.49508848786354065, 'eval_accuracy': 0.8473053892215568, 'eval_f1': 0.8365796238817554, 'eval_precision': 0.858505437109551, 'eval_recall': 0.8473053892215568, 'eval_runtime': 3.1071, 'eval_samples_per_second': 107.495, 'eval_steps_per_second': 27.035, 'epoch': 1.0}
{'loss': 0.7753, 'learning_rate': 7.5621890547263685e-06, 'epoch': 1.87}
{'eval_loss': 0.2584662437438965, 'eval_accuracy': 0.9161676646706587, 'eval_f1': 0.9135606098355845, 'eval_precision': 0.9175004217050559, 'eval_recall': 0.9161676646706587, 'eval_runtime': 2.9737, 'eval_samples_per_second': 112.316, 'eval_steps_per_second': 28.247, 'epoch': 2.0}
{'eval_loss': 0.19924236834049225, 'eval_accuracy': 0.9461077844311377, 'eval_f1': 0.9438198275741255, 'eval_precision': 0.9458702313847644, 'eval_recall': 0.9461077844311377, 'eval_runtime': 2.9349, 'eval_samples_per_second': 113.802, 'eval_steps_per_second': 28.621, 'epoch': 3.0}
{'train_runtime': 100.0631, 'train_samples_per_second': 80.139, 'train_steps_per_second': 8.035, 'train_loss': 0.5679708547260037, 'epoch': 3.0}
Training completed. Evaluating on validation dataset...
Swin Trasnformer Validation results: {'eval_loss': 0.2048904299736023, 'eval_accuracy': 0.937125748502994, 'eval_f1': 0.9349254777341957, 'eval_precision': 0.9377230228538138, 'eval_recall': 0.937125748502994, 'eval_runtime': 3.036, 'eval_samples_per_second': 110.014, 'eval_steps_per_second': 27.668, 'epoch': 3.0}
******************************************************************************************************************************************************
Swin Trasnformer Evaluating on test dataset...
Test results: {'eval_loss': 0.25044533610343933, 'eval_accuracy': 0.9164179104477612, 'eval_f1': 0.9146917823085556, 'eval_precision': 0.9188240165631468, 'eval_recall': 0.9164179104477612, 'eval_runtime': 3.0492, 'eval_samples_per_second': 109.866, 'eval_steps_per_second': 27.549, 'epoch': 3.0}
******************************************************************************************************************************************************
