******************************************************************************************************************************************************
{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=550x442 at 0x151844193ED0>, 'label': 0}
******************************************************************************************************************************************************
{0: 'Line graph_chart', 1: 'NLP text_grammar_eg', 2: 'Screenshots', 3: 'algorithms', 4: 'architecture diagram', 5: 'bar charts', 6: 'boxplots', 7: 'confusion matrix', 8: 'graph', 9: 'maps', 10: 'natural images', 11: 'neural networks', 12: 'pareto', 13: 'pie chart', 14: 'scatter plot', 15: 'tables', 16: 'trees', 17: 'venn diagram', 18: 'word cloud'}
******************************************************************************************************************************************************
{'image': [<PIL.PngImagePlugin.PngImageFile image mode=RGB size=550x442 at 0x1518BFBED5D0>, <PIL.PngImagePlugin.PngImageFile image mode=RGB size=569x305 at 0x1518BFBEFC10>], 'label': [0, 0], 'pixel_values': [tensor([[[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]],

        [[1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         ...,
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.],
         [1., 1., 1.,  ..., 1., 1., 1.]]]), tensor([[[ 0.7255,  0.7098,  0.7098,  ...,  0.7098,  0.7098,  0.7098],
         [-0.0039,  0.0745,  0.0745,  ...,  0.0745,  0.0745, -0.0039],
         [ 0.3647,  0.7882,  0.7882,  ...,  0.7882,  0.7882,  0.5294],
         ...,
         [ 0.5137,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  0.7098],
         [ 0.5137,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  0.7098],
         [-0.2314, -0.0824, -0.0824,  ..., -0.0824, -0.0824, -0.1686]],

        [[ 0.7255,  0.7098,  0.7098,  ...,  0.7098,  0.7098,  0.7098],
         [-0.0039,  0.0745,  0.0745,  ...,  0.0745,  0.0745, -0.0039],
         [ 0.3647,  0.7882,  0.7882,  ...,  0.7882,  0.7882,  0.5294],
         ...,
         [ 0.5137,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  0.7098],
         [ 0.5137,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  0.7098],
         [-0.2314, -0.0824, -0.0824,  ..., -0.0824, -0.0824, -0.1686]],

        [[ 0.7255,  0.7098,  0.7098,  ...,  0.7098,  0.7098,  0.7098],
         [-0.0039,  0.0745,  0.0745,  ...,  0.0745,  0.0745, -0.0039],
         [ 0.3647,  0.7882,  0.7882,  ...,  0.7882,  0.7882,  0.5294],
         ...,
         [ 0.5137,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  0.7098],
         [ 0.5137,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  0.7098],
         [-0.2314, -0.0824, -0.0824,  ..., -0.0824, -0.0824, -0.1686]]])]}
******************************************************************************************************************************************************
Printing the shape of the tensor
pixel_values torch.Size([4, 3, 224, 224])
******************************************************************************************************************************************************
Printing the shape of the tensor
labels torch.Size([4])
******************************************************************************************************************************************************
{'eval_loss': 1.490425944328308, 'eval_accuracy': 0.8173652694610778, 'eval_f1': 0.7979737176480299, 'eval_precision': 0.8288179923160127, 'eval_recall': 0.8173652694610778, 'eval_runtime': 3.2339, 'eval_samples_per_second': 103.282, 'eval_steps_per_second': 25.975, 'epoch': 1.0}
{'loss': 1.6849, 'learning_rate': 1.0671641791044778e-05, 'epoch': 1.87}
{'eval_loss': 0.9864873886108398, 'eval_accuracy': 0.8922155688622755, 'eval_f1': 0.8832120771957395, 'eval_precision': 0.8887730883147372, 'eval_recall': 0.8922155688622755, 'eval_runtime': 3.2024, 'eval_samples_per_second': 104.298, 'eval_steps_per_second': 26.231, 'epoch': 2.0}
{'eval_loss': 0.7818188071250916, 'eval_accuracy': 0.9311377245508982, 'eval_f1': 0.9258373868860438, 'eval_precision': 0.9281815026892983, 'eval_recall': 0.9311377245508982, 'eval_runtime': 3.1061, 'eval_samples_per_second': 107.529, 'eval_steps_per_second': 27.043, 'epoch': 3.0}
{'loss': 0.7907, 'learning_rate': 1.3432835820895524e-06, 'epoch': 3.73}
{'eval_loss': 0.7123270630836487, 'eval_accuracy': 0.9401197604790419, 'eval_f1': 0.9351223516804145, 'eval_precision': 0.9353401113313211, 'eval_recall': 0.9401197604790419, 'eval_runtime': 3.1092, 'eval_samples_per_second': 107.422, 'eval_steps_per_second': 27.016, 'epoch': 4.0}
{'train_runtime': 175.0858, 'train_samples_per_second': 61.067, 'train_steps_per_second': 6.123, 'train_loss': 1.1994700894426944, 'epoch': 4.0}
Training completed. Evaluating on validation dataset...
Validation results: {'eval_loss': 0.7141688466072083, 'eval_accuracy': 0.937125748502994, 'eval_f1': 0.9320140094435974, 'eval_precision': 0.9337703709839873, 'eval_recall': 0.937125748502994, 'eval_runtime': 3.1025, 'eval_samples_per_second': 107.656, 'eval_steps_per_second': 27.075, 'epoch': 4.0}
******************************************************************************************************************************************************
Evaluating on test dataset...
Test results: {'eval_loss': 0.7425796985626221, 'eval_accuracy': 0.9104477611940298, 'eval_f1': 0.9053109496767018, 'eval_precision': 0.9068340800645549, 'eval_recall': 0.9104477611940298, 'eval_runtime': 3.1316, 'eval_samples_per_second': 106.975, 'eval_steps_per_second': 26.824, 'epoch': 4.0}
******************************************************************************************************************************************************
